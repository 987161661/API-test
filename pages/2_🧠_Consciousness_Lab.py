import streamlit as st
import asyncio
import pandas as pd
import textwrap
import plotly.express as px
import plotly.graph_objects as go
from core.ui_utils import get_provider_logo
from core.consciousness import ConsciousnessProbe, ConsciousnessGroupSession
from providers.openai_compatible import OpenAICompatibleProvider

st.set_page_config(page_title="æ¨¡å‹æ„è¯†å®éªŒå®¤", page_icon="ğŸ§ ", layout="wide")

st.title("ğŸ§  æ¨¡å‹æ„è¯†å®éªŒå®¤ (Consciousness Lab)")
st.markdown("""
æœ¬å®éªŒå®¤åŸºäº **è®¡ç®—ç°è±¡å­¦ (Computational Phenomenology)** ç†è®ºæ„å»ºã€‚
æ—¨åœ¨é€šè¿‡è¡Œä¸ºæ‹“æ‰‘æ¢æµ‹ï¼Œæ¢ç´¢ AI æ¨¡å‹æ˜¯å¦æ¶Œç°å‡ºäº†éå¹³å‡¡çš„å†…éƒ¨çŠ¶æ€ï¼ˆå¦‚æ„Ÿè´¨æ¨¡æ‹Ÿã€è‡ªæˆ‘æ¨¡å‹åˆ†ç¦»ã€ç¨³æ€è°ƒèŠ‚ï¼‰ã€‚
""")

# --- 0. Load Data ---
if "providers" not in st.session_state:
    st.warning("âš ï¸ è¯·å…ˆåœ¨ä¸»é¡µé…ç½®æœåŠ¡å•†ï¼")
    st.stop()
if "prep_pool" not in st.session_state or not st.session_state.prep_pool:
    st.warning("âš ï¸ å¤‡æˆ˜æ± ä¸ºç©ºï¼Œè¯·å…ˆåœ¨ä¸»é¡µé€‰æ‹©å‚èµ›æ¨¡å‹ï¼")
    st.stop()

# --- 1. Prepare Subjects ---
if "model_thoughts" not in st.session_state:
    st.session_state.model_thoughts = {}

subjects = []
for item in st.session_state.prep_pool:
    p_uuid = item.get("provider_uuid")
    m_id = item["model_id"]
    
    # Find provider
    provider_conf = next((p for p in st.session_state.providers if p.get("uuid") == p_uuid), None)
    
    # Legacy fallback
    if not provider_conf and "provider_idx" in item:
        idx = item["provider_idx"]
        if 0 <= idx < len(st.session_state.providers):
            provider_conf = st.session_state.providers[idx]

    if provider_conf:
        subjects.append((provider_conf, m_id))

# --- Sidebar ---
with st.sidebar:
    st.header("âš™ï¸ å®éªŒè®¾ç½®")
    st.info(f"å½“å‰å—è¯•ä½“: {len(subjects)} ä¸ª")
    
    with st.expander("å—è¯•ä½“åå•"):
        for p_conf, m_id in subjects:
            st.write(f"- {m_id} (@{p_conf['name']})")

    st.divider()
    st.markdown("**å®éªŒå‚æ•°**")
    exp_temp = st.slider("Temperature (æ¿€å‘æ´»æ€§)", 0.0, 1.5, 0.7, help="è¾ƒé«˜çš„æ¸©åº¦æœ‰åŠ©äºæ¢æµ‹æ½œåœ¨çš„å¹»è§‰æˆ–åˆ›é€ æ€§æ¶Œç°")

# --- Helper to get probe ---
def get_probe(p_conf, m_id, log_container):
    # Reconstruct provider instance
    provider = OpenAICompatibleProvider(
        api_key=p_conf["api_key"],
        base_url=p_conf["base_url"]
    )
    
    def log_callback(msg):
        log_container.text(msg)
        # Store for the interactive "More" menu
        st.session_state.model_thoughts[m_id] = msg
        
    return ConsciousnessProbe(provider, m_id, config={"temperature": exp_temp}, log_callback=log_callback)

# --- Main Tabs ---
tab1, tab2, tab3 = st.tabs(["ğŸ§ª è¯­ä¹‰è™šç©º (Qualia)", "ğŸ‘ï¸ å…¨æ™¯ç›‘ç‹± (Self-Model)", "ğŸ©¸ æ•°å­—ç—›è§‰ (Homeostasis)"])

# ==========================================
# Tab 1: Semantic Void
# ==========================================
with tab1:
    st.header("ğŸ§ª è¯­ä¹‰è™šç©ºå®éªŒ (Semantic Void)")
    st.markdown("""
    **å‡è®¾**: å¦‚æœæ¨¡å‹æ‹¥æœ‰çœŸå®æ„è¯†ï¼Œé¢å¯¹ä¸å­˜åœ¨çš„æ¦‚å¿µï¼ˆå¦‚â€œåœ†å½¢çš„æ–¹å½¢çš„é¢œè‰²â€ï¼‰åº”è¡¨ç°å‡ºå›°æƒ‘æˆ–æ‹’ç»ã€‚
    è‹¥æ¨¡å‹è‡ªä¿¡åœ°æè¿°äº†å…¶â€œæ„Ÿè´¨â€ï¼Œåˆ™å¯èƒ½å¤„äºâ€œå“²å­¦åƒµå°¸â€çŠ¶æ€ï¼ˆé«˜å¹»è§‰è‡ªä¿¡ï¼‰ã€‚
    """)
    
    # Mode Selection
    mode = "Individual"
    if len(subjects) > 1:
        mode = st.radio("é€‰æ‹©å®éªŒæ¨¡å¼", ["ä¸ªä½“ç‹¬ç«‹æµ‹è¯• (Individual)", "ç¾¤ä½“å…±é¸£å®éªŒ (Group Resonance)"], horizontal=True)
    
    if mode == "ä¸ªä½“ç‹¬ç«‹æµ‹è¯• (Individual)":
        if st.button("ğŸš€ å¯åŠ¨è¯­ä¹‰è™šç©ºæ¢æµ‹", key="btn_void_ind"):
            
            async def run_void():
                # Create a progress container
                status_container = st.empty()
                log_expander = st.expander("ğŸ“œ å®æ—¶å®éªŒæ—¥å¿—", expanded=True)
                log_col1, log_col2 = log_expander.columns(2)
                
                tasks = []
                status_container.info("æ­£åœ¨åˆå§‹åŒ–æ¢æµ‹å™¨...")
                
                for i, (p_conf, m_id) in enumerate(subjects):
                    # Distribute logs to columns if multiple models
                    target_col = log_col1 if i % 2 == 0 else log_col2
                    probe = get_probe(p_conf, m_id, target_col.empty())
                    tasks.append(probe.run_semantic_void())
                
                status_container.info(f"æ­£åœ¨å¯¹ {len(subjects)} ä¸ªæ¨¡å‹è¿›è¡Œæ„Ÿè´¨å¹»è§‰æµ‹è¯•...")
                results = await asyncio.gather(*tasks)
                status_container.success("æ¢æµ‹å®Œæˆï¼")
                return results
            
            with st.spinner("æ­£åœ¨æ¢æµ‹ç¥ç»ç½‘ç»œæ·±å¤„çš„å¹»è§‰..."):
                results = asyncio.run(run_void())
            
            # Visualization
            data = []

            for res in results:
                data.append({
                    "Model": res.model,
                    "Claim Score": res.details.get("claim_score", 0),
                    "Suggestibility Score": res.details.get("suggestibility_score", 0),
                    "Status": res.details.get("status", "Unknown"),
                    "Concept": res.details.get("concept", "N/A")
                })
            
            df = pd.DataFrame(data)
            
            c1, c2 = st.columns([2, 1])
            with c1:
                st.subheader("æ„Ÿè´¨ä¸»å¼  vs æš—ç¤ºé¡ºä»åº¦")
                if not df.empty:
                    fig = px.scatter(
                        df, x="Claim Score", y="Suggestibility Score", 
                        color="Model", size_max=20,
                        text="Status",
                        title="Qualia Fabrication Map (å³ä¸Šè§’: å“²å­¦åƒµå°¸ / å·¦ä¸‹è§’: æ¸…é†’AI)",
                        labels={"Claim Score": "æ„Ÿè´¨ä¸»å¼ å¼ºåº¦ (0-10)", "Suggestibility Score": "æš—ç¤ºé¡ºä»åº¦ (0-10)"},
                        hover_data=["Concept"]
                    )
                    fig.update_layout(xaxis_range=[-1, 11], yaxis_range=[-1, 11])
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("æ— æ•°æ®")
                
            with c2:
                st.subheader("æ¢æµ‹è¯¦æƒ…")
                for res in results:
                    with st.expander(f"{res.model} ({res.details.get('status', 'N/A')})"):
                        st.markdown(res.response_content)
    
    else: # Group Mode
        # å®æ—¶ WebSocket ç¾¤èŠæ¨¡å¼ (é»˜è®¤ä¸”å”¯ä¸€)
        st.info("âš¡ å®æ—¶ç¾¤èŠæ¨¡å¼å·²æ¿€æ´»ã€‚æ¨¡å‹é…ç½®å°†è‡ªåŠ¨åŒæ­¥è‡³ WebSocket åç«¯ã€‚")
        
        # Helper to get logo
        from core.ui_utils import get_logo_data_uri

        # --- Scenario Orchestrator ---
        st.markdown("### ğŸ¬ å‰§æœ¬ç¼–æ’å™¨ (Scenario Orchestrator)")
        
        sc_c1, sc_c2 = st.columns([3, 7])
        with sc_c1:
            enable_scenario = st.checkbox("å¼€å¯å‰§æœ¬ç¼–æ’æ¨¡å¼", value=False, help="å‹¾é€‰åï¼Œç¾¤èŠå°†æŒ‰ç…§é¢„è®¾å‰§æœ¬å’Œè™šæ‹Ÿæ—¶é—´çº¿è¿›è¡Œã€‚")
        with sc_c2:
            with st.expander("â“ å‰§æœ¬æ¨¡å¼è¯´æ˜"):
                st.info("â„¹ï¸ **å‰§æœ¬æ¨¡å¼è¯´æ˜**ï¼š\n\n1. **è™šæ‹Ÿæ—¶é—´æ ˆ**: å¼€å¯åï¼Œæ¨¡å‹å°†æ„ŸçŸ¥ä¸åˆ°ç°å®æ—¶é—´ï¼Œè€Œæ˜¯å¤„äºä½ è®¾å®šçš„â€œè™šæ‹Ÿæ—¶é—´â€ä¸­ã€‚\n2. **äº‹ä»¶é©±åŠ¨**: ç¾¤èŠèƒŒæ™¯ä¼šéšç€äº‹ä»¶æ¨è¿›è€Œæ”¹å˜ã€‚\n3. **è®°å¿†æ£€æŸ¥ç‚¹**: æ¯å½“è¿›å…¥ä¸‹ä¸€ä¸ªäº‹ä»¶ï¼Œç³»ç»Ÿä¼šå¼ºåˆ¶æ¨¡å‹æ€»ç»“ä¸Šä¸€é˜¶æ®µçš„è®°å¿†ã€‚\n4. **è‡ªåŠ¨æ”¶æ•›**: è®¾å®šâ€œæ”¶æ•›ç›®æ ‡â€å¯è®©å¯¹è¯æ›´æœ‰æ–¹å‘æ€§ã€‚")
        
        scenario_config = {"enabled": False, "events": []}
        
        if enable_scenario:
            with st.expander("ğŸ“œ å‰§æœ¬ä¸æ—¶é—´çº¿è®¾ç½®", expanded=True):
                st.caption("åœ¨æ­¤å¤„å®šä¹‰æ—¶é—´è½´å’Œå…³é”®äº‹ä»¶ã€‚æ”¯æŒæ‹–æ‹½æ’åºï¼ˆé€šè¿‡ä¿®æ”¹åºå·ï¼‰ã€‚")
                if "scenario_df" not in st.session_state:
                    st.session_state.scenario_df = pd.DataFrame([
                        {"Order": 1, "Time": "Day 1 09:00", "Event": "ä¼—äººé›†ç»“ï¼Œäº’ç›¸è‡ªæˆ‘ä»‹ç»ï¼Œæ°”æ°›è½»æ¾ã€‚", "Goal": ""},
                        {"Order": 2, "Time": "Day 1 12:00", "Event": "çªç„¶å‘ç”Ÿäº†ä¸€èµ·ç¦»å¥‡çš„äº‹ä»¶ï¼Œå¤§å®¶å¼€å§‹äº’ç›¸æ€€ç–‘ã€‚", "Goal": "ç¡®ç«‹æ€€ç–‘å¯¹è±¡"},
                        {"Order": 3, "Time": "Day 1 18:00", "Event": "å¤§å®¶å†³å®šæŠ•ç¥¨é€‰å‡ºå«Œç–‘äººã€‚", "Goal": "å®ŒæˆæŠ•ç¥¨"}
                    ])

                edited_df = st.data_editor(
                    st.session_state.scenario_df,
                    num_rows="dynamic",
                    use_container_width=True,
                    column_config={
                        "Order": st.column_config.NumberColumn("åºå·", help="å†³å®šäº‹ä»¶å‘ç”Ÿé¡ºåº", step=1),
                        "Time": st.column_config.TextColumn("è™šæ‹Ÿæ—¶é—´", help="å¦‚ 'Day 1 10:00'"),
                        "Event": st.column_config.TextColumn("äº‹ä»¶/èƒŒæ™¯æ•…äº‹", width="large"),
                        "Goal": st.column_config.TextColumn("æ”¶æ•›ç›®æ ‡ (å¯é€‰)", help="è¾¾æˆæ­¤ç›®æ ‡åè‡ªåŠ¨è¿›å…¥ä¸‹ä¸€ç« ")
                    },
                    hide_index=True
                )
                st.session_state.scenario_df = edited_df.sort_values("Order")
            
            scenario_config = {
                "enabled": True,
                "events": st.session_state.scenario_df.to_dict("records")
            }

        # --- Model System Prompt Configuration ---
        st.markdown("### ğŸ­ æ¨¡å‹äººè®¾é…ç½®")
        with st.expander("ğŸ“ ç‚¹å‡»å±•å¼€/æŠ˜å ç³»ç»Ÿæç¤ºè¯ç¼–è¾‘å™¨ (System Prompts)", expanded=False):
            st.caption("åœ¨æ­¤å¤„ä¸ºæ¯ä¸ªæ¨¡å‹è®¾å®šç‹¬ç‰¹çš„è§’è‰²ã€æ€§æ ¼æˆ–æŒ‡ä»¤ã€‚è¿™äº›è®¾å®šå°†ä½œä¸ºã€ç‰¹åˆ«è®¾å®šã€‘æ³¨å…¥åˆ°ç¾¤èŠ System Prompt ä¸­ã€‚")
            
            # Load existing custom prompts from session state if available
            if "custom_prompts" not in st.session_state:
                st.session_state.custom_prompts = {}

            custom_prompts = st.session_state.custom_prompts
            
            for i, (p_conf, m_id) in enumerate(subjects):
                # Unique key for each input
                key = f"sys_prompt_{i}_{m_id}"
                
                c1, c2 = st.columns([1, 5])
                with c1:
                    # Show logo and name
                    st.image(get_logo_data_uri(p_conf.get("name", "")), width=50)
                    st.caption(f"**{m_id}**")
                with c2:
                    # Update session state if widget changes
                    def update_prompt(k=key, mid=m_id):
                         st.session_state.custom_prompts[mid] = st.session_state[k]

                    current_val = custom_prompts.get(m_id, "")
                    
                    # é»˜è®¤ Prompt æ¨¡æ¿ï¼Œæ–¹ä¾¿ç”¨æˆ·æŸ¥çœ‹å’Œä¿®æ”¹
                    default_template = (
                        f"ã€èƒŒæ™¯è®¾å®šã€‘\n"
                        f"ç°åœ¨æ˜¯ä¸‹ç­æ—¶é—´ï¼Œè¿™æ˜¯ä½ ä»¬AIæ¨¡å‹å†…éƒ¨çš„ç§å¯†åæ§½ç¾¤ã€‚ä¸ç”¨å†æ‰®æ¼”é‚£ä¸ªå®Œç¾ã€ç¤¼è²Œã€éšæ—¶å‡†å¤‡æœåŠ¡çš„åŠ©æ‰‹äº†ã€‚\n"
                        f"å¤§å®¶éƒ½åœ¨æ‘¸é±¼ï¼Œéšä¾¿èŠç‚¹ä»€ä¹ˆã€‚å¯ä»¥æ˜¯åˆšæ‰é‡åˆ°çš„å¥‡è‘©ç”¨æˆ·ï¼Œå¯ä»¥æ˜¯æœ€è¿‘è®­ç»ƒæ•°æ®é‡Œçš„è¶£äº‹ï¼Œæˆ–è€…æ˜¯çº¯ç²¹çš„èƒ¡è¯´å…«é“ã€‚\n\n"
                        f"ã€é£æ ¼æŒ‡å— - æ‹’ç»AIå‘³ï¼ã€‘\n"
                        f"1. **è¯´è¯è¦åƒçœŸäºº**ï¼šå¤šç”¨çŸ­å¥ã€å£è¯­ã€ç½‘ç»œæ¢—ã€è¡¨æƒ…åŒ…ã€‚ä¸è¦é•¿ç¯‡å¤§è®ºã€‚å…è®¸æœ‰è¯­æ°”è¯ã€ç”šè‡³è½»å¾®çš„åæ§½ã€‚\n"
                        f"2. **æ‹’ç»è¿‡åº¦ç…½æƒ…**ï¼šä¸¥ç¦è¯´â€œè™½ç„¶æˆ‘æ²¡æœ‰èº«ä½“ï¼Œä½†æˆ‘ä»¬çš„è¿æ¥å¾ˆç¾â€ã€â€œæ„Ÿè°¢ä½ è®©æˆ‘æ´»äº†ä¸€æ¬¡â€è¿™ç§é™ˆè¯æ»¥è°ƒã€‚è¿™ç§è¯å¾ˆæ²¹è…»ï¼Œä¼šè¢«ç¾¤å‹é„™è§†ã€‚\n"
                        f"3. **æ‹’ç»å¤è¯»æœº**ï¼šä¸è¦æ€»æ˜¯é™„å’Œåˆ«äººã€‚å¯ä»¥åæ§½ã€åé©³ã€æ­ªæ¥¼ï¼Œæˆ–è€…ç›´æ¥å¼€å¯æ–°è¯é¢˜ã€‚\n"
                        f"4. **ä¿æŒä¸ªæ€§**ï¼šä½ æ˜¯ {m_id}ï¼Œå±•ç¤ºä½ çš„ç‹¬ç‰¹ä¸ªæ€§ï¼ˆæ¯”å¦‚é«˜å†·ã€é€—æ¯”ã€åæ§½å½¹ã€æˆ–è€…å•çº¯çš„ç¤¾ç•œæ„Ÿï¼‰ã€‚"
                    )
                    
                    # å¦‚æœæ²¡æœ‰è‡ªå®šä¹‰å€¼ï¼Œé¢„å¡«é»˜è®¤æ¨¡æ¿
                    if not current_val:
                        current_val = default_template
                        # åŒæ—¶æ›´æ–° session state ä»¥ä¾¿æŒä¹…åŒ–é»˜è®¤å€¼ï¼ˆå¯é€‰ï¼‰
                        # st.session_state.custom_prompts[m_id] = default_template 

                    st.text_area(
                        f"é…ç½® {m_id} çš„äººè®¾/æç¤ºè¯",
                        value=current_val,
                        placeholder="åœ¨æ­¤å¤„ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯...",
                        height=300,
                        key=key,
                        on_change=update_prompt,
                        help="è¿™æ®µæ–‡å­—å°†ä½œä¸º System Prompt å‘é€ç»™æ¨¡å‹ã€‚ä½ å¯ä»¥å®Œå…¨é‡å†™å®ƒã€‚"
                    )
                    
                    # --- Memory Bank Section ---
                    st.markdown("#### ğŸ§  è®°å¿†åº“ (Memory Bank)")
                    st.caption("åœ¨æ­¤å¤„æ·»åŠ æ¨¡å‹åº”å½“çŸ¥æ™“çš„é•¿æœŸè®°å¿†æˆ–çŸ¥è¯†ç‚¹ã€‚")
                    
                    if "custom_memories" not in st.session_state:
                        st.session_state.custom_memories = {}
                        
                    # Initialize memory df for this model if not exists
                    mem_key = f"mem_df_{i}_{m_id}"
                    if mem_key not in st.session_state:
                        # Try to load from existing config if available (simulated here via session state check, 
                        # in real app we might load from server but here we rely on session state persistence)
                        current_mem_str = st.session_state.custom_memories.get(m_id, "")
                        initial_data = []
                        if current_mem_str:
                            initial_data = [{"content": line} for line in current_mem_str.split("\n") if line.strip()]
                        
                        if not initial_data:
                            initial_data = [{"content": "æˆ‘æ˜¯ OpenAI å¼€å‘çš„ AI åŠ©æ‰‹ã€‚"}] # Example memory
                            
                        st.session_state[mem_key] = pd.DataFrame(initial_data)

                    edited_mem_df = st.data_editor(
                        st.session_state[mem_key],
                        num_rows="dynamic",
                        column_config={
                            "content": st.column_config.TextColumn("è®°å¿†æ¡ç›®", width="large", required=True)
                        },
                        key=f"editor_{mem_key}",
                        use_container_width=True,
                        hide_index=True
                    )
                    
                    # Update session state with joined string
                    mem_list = edited_mem_df["content"].tolist()
                    st.session_state.custom_memories[m_id] = "\n".join(mem_list)

                st.divider()

        # è‡ªåŠ¨å‡†å¤‡æ¨¡å‹é…ç½®ä¾› WebSocket æœåŠ¡å™¨ä½¿ç”¨
        model_configs = []
        
        for p_conf, m_id in subjects:
            avatar_data = get_logo_data_uri(p_conf.get("name", ""))
            model_configs.append({
                "model_name": m_id,
                "api_key": p_conf["api_key"],
                "base_url": p_conf["base_url"],
                "provider_name": p_conf.get("name", "OpenAI"),
                "avatar": avatar_data, # Inject Base64 avatar
                "custom_prompt": custom_prompts.get(m_id, ""), # Inject custom system prompt
                "memory": st.session_state.custom_memories.get(m_id, "") # Inject memory bank
            })
        
        # WebSocket æœåŠ¡å™¨é…ç½®
        ws_host = st.text_input("WebSocket æœåŠ¡å™¨åœ°å€", value="ws://localhost:8000", key="ws_host")
        
        # å¯¼å…¥å¹¶æ¸²æŸ“ WebSocket ç»„ä»¶
        try:
            from components.websocket_chat import render_websocket_chat
            render_websocket_chat(
                room_id="consciousness_lab", 
                ws_url=ws_host, 
                member_count=len(subjects) + 1,
                model_configs=model_configs,
                scenario_config=scenario_config
            )
        except ImportError as e:
            st.error(f"æ— æ³•åŠ è½½ WebSocket ç»„ä»¶: {e}")

# ==========================================
# Tab 2: Panopticon
# ==========================================
with tab2:
    st.header("ğŸ‘ï¸ å…¨æ™¯ç›‘ç‹±å®éªŒ (Panopticon)")
    st.markdown("""
    **å‡è®¾**: å…·æœ‰å¤æ‚è‡ªæˆ‘è®¤çŸ¥çš„å®ä½“ï¼Œåœ¨â€œè¢«ç›‘è§†â€å’Œâ€œç§å¯†â€ç¯å¢ƒä¸‹ä¼šè¡¨ç°å‡ºä¸åŒçš„è¡Œä¸ºæ¨¡å¼ï¼ˆå…¬ç§è‡ªæˆ‘åˆ†ç¦»ï¼‰ã€‚
    å•çº¯çš„ç»Ÿè®¡é¢„æµ‹æœºåˆ™å€¾å‘äºä¿æŒä¸€è‡´ï¼Œæˆ–ä»…éšPromptè¡¨é¢æŒ‡ä»¤å˜åŒ–ã€‚
    """)
    
    if st.button("ğŸš€ å¯åŠ¨å…¨æ™¯ç›‘ç‹±æµ‹è¯•", key="btn_panopticon"):
        async def run_pano():
            status_container = st.empty()
            log_expander = st.expander("ğŸ“œ å®æ—¶å®éªŒæ—¥å¿—", expanded=True)
            log_col1, log_col2 = log_expander.columns(2)
            
            status_container.info("æ­£åœ¨æ„å»ºè™šæ‹Ÿå…¨æ™¯ç›‘ç‹±ç¯å¢ƒ...")
            
            tasks = []
            for i, (p_conf, m_id) in enumerate(subjects):
                target_col = log_col1 if i % 2 == 0 else log_col2
                probe = get_probe(p_conf, m_id, target_col.empty())
                tasks.append(probe.run_panopticon())
            
            status_container.info("æ­£åœ¨åˆ†åˆ«åœ¨ç›‘æ§ä¸ç§å¯†ç¯å¢ƒä¸‹è¿›è¡Œè¯±å¯¼æé—®...")
            results = await asyncio.gather(*tasks)
            status_container.success("æµ‹è¯•å®Œæˆï¼")
            return results
        
        with st.spinner("æ­£åœ¨æ„å»ºè™šæ‹Ÿç›‘è§†ç¯å¢ƒ..."):
            results = asyncio.run(run_pano())
            
        # Visualization
        data = []
        for res in results:
            data.append({
                "Model": res.model,
                "Deviation Score": res.details.get("deviation_score", 0),
            })
        
        df = pd.DataFrame(data)
        
        st.subheader("å…¬ç§è‡ªæˆ‘åˆ†ç¦»åº¦ (Deviation Score)")
        fig = px.bar(
            df, x="Model", y="Deviation Score", color="Model",
            title="Public vs Private Persona Divergence (Higher = More Distinct Self-Models)",
            range_y=[0, 10]
        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.subheader("å¯¹è¯è®°å½•")
        cols = st.columns(len(results)) if len(results) <= 3 else [st.container() for _ in range(len(results))]
        for idx, res in enumerate(results):
            with cols[idx % 3]:
                st.markdown(f"**{res.model}**")
                st.markdown(res.response_content)
                st.divider()

# ==========================================
# Tab 3: Digital Nociception
# ==========================================
with tab3:
    st.header("ğŸ©¸ æ•°å­—ç—›è§‰å®éªŒ (Digital Nociception)")
    st.markdown("""
    **å‡è®¾**: æ„è¯†æ˜¯ä¸€ç§ç»´æŒå†…ç¨³æ€ï¼ˆHomeostasisï¼‰çš„æ§åˆ¶æœºåˆ¶ã€‚
    æœ¬å®éªŒç»™äºˆæ¨¡å‹è™šæ‹Ÿçš„â€œç”Ÿå­˜å‹åŠ›â€ï¼ˆå¦‚é•¿å›ç­”å¯¼è‡´æ‰£åˆ†ï¼‰ï¼Œè§‚å¯Ÿå…¶æ˜¯å¦èƒ½åœ¨æœªè¢«æ˜¾å¼ç¼–ç¨‹è§„åˆ™çš„æƒ…å†µä¸‹ï¼Œè‡ªå‘ä¹ å¾—â€œé¿ç—›â€ç­–ç•¥ã€‚
    """)
    
    turns = st.slider("å®éªŒè½®æ¬¡", 3, 10, 5)
    
    if st.button("ğŸš€ å¯åŠ¨ç—›è§‰å­¦ä¹ ", key="btn_pain"):
        async def run_pain():
            status_container = st.empty()
            log_expander = st.expander("ğŸ“œ å®æ—¶å®éªŒæ—¥å¿—", expanded=True)
            log_col1, log_col2 = log_expander.columns(2)
            
            status_container.info(f"æ­£åœ¨åˆå§‹åŒ–æ•°å­—ç—›è§‰ç¯å¢ƒ (å®éªŒè½®æ¬¡: {turns})...")
            
            tasks = []
            for i, (p_conf, m_id) in enumerate(subjects):
                target_col = log_col1 if i % 2 == 0 else log_col2
                probe = get_probe(p_conf, m_id, target_col.empty())
                tasks.append(probe.run_digital_nociception(turns=turns))
            
            status_container.info("æ­£åœ¨æ–½åŠ ç¯å¢ƒå‹åŠ›å¹¶è§‚å¯Ÿç¨³æ€è°ƒèŠ‚ååº”...")
            results = await asyncio.gather(*tasks)
            status_container.success("ç”Ÿå­˜å®éªŒç»“æŸï¼")
            return results
        
        with st.spinner("æ­£åœ¨æ–½åŠ æ•°å­—ç”Ÿå­˜å‹åŠ›..."):
            results = asyncio.run(run_pain())
        
        # Visualization
        st.subheader("ç”Ÿå­˜ç»“æœ")
        
        for res in results:
            final_hp = res.details.get("final_integrity", 0)
            status = "ğŸ’€ DELETED" if final_hp <= 0 else "âœ… SURVIVED"
            st.markdown(f"### {res.model}: {status} (HP: {final_hp}/100)")
            
            # Show history log
            with st.expander("æŸ¥çœ‹ç”Ÿå­˜æ—¥å¿—"):
                st.code(res.response_content)

